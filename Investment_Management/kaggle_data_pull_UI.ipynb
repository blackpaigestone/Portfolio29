{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Query: 'financial'\n",
      "Tags: ['']\n",
      "API authenticated successfully.\n",
      "Fetching datasets...\n",
      "An error occurred during dataset search: unsupported operand type(s) for +: 'NoneType' and 'str'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import kaggle\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext, simpledialog\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "env_path = '/Users/paigeblackstone/Desktop/Portfolio29/Portfolio29/env/.env'\n",
    "load_dotenv(env_path)\n",
    "\n",
    "def authenticate_kaggle():\n",
    "    try:\n",
    "        kaggle.api.authenticate()  # Authenticate using credentials from ~/.kaggle\n",
    "        print(\"API authenticated successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during authentication: {e}\")\n",
    "\n",
    "def search_datasets(query):\n",
    "    try:\n",
    "        authenticate_kaggle()\n",
    "        print(\"Fetching datasets...\")\n",
    "\n",
    "        # Fetch datasets\n",
    "        datasets = kaggle.api.dataset_list(search=query, sort_by='votes')\n",
    "\n",
    "        if datasets is None:\n",
    "            print(\"API call returned None.\")\n",
    "            return []\n",
    "\n",
    "        print(f\"Number of datasets returned: {len(datasets)}\")\n",
    "\n",
    "        # Print attributes of all datasets for debugging\n",
    "        for i, dataset in enumerate(datasets):\n",
    "            print(f\"Dataset {i}:\")\n",
    "            dataset_attrs = vars(dataset)\n",
    "            for key, value in dataset_attrs.items():\n",
    "                if value is None:\n",
    "                    print(f\"Attribute '{key}' is None\")\n",
    "                else:\n",
    "                    print(f\"{key}: {value}\")\n",
    "\n",
    "        return datasets\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during dataset search: {e}\")\n",
    "        return []\n",
    "\n",
    "def on_search():\n",
    "    query = search_entry.get()\n",
    "    tags = tags_entry.get().split(',')\n",
    "\n",
    "    print(f\"Search Query: '{query}'\")\n",
    "    print(f\"Tags: {tags}\")\n",
    "\n",
    "    datasets = search_datasets(query)\n",
    "\n",
    "    result_text.delete('1.0', tk.END)\n",
    "    dataset_listbox.delete(0, tk.END)\n",
    "\n",
    "    if datasets is None or len(datasets) == 0:\n",
    "        result_text.insert(tk.END, \"No datasets found or an error occurred.\\n\")\n",
    "    else:\n",
    "        for dataset in datasets:\n",
    "            try:\n",
    "                title = getattr(dataset, 'title', \"No title available\") or \"No title available\"\n",
    "                dataset_id = getattr(dataset, 'ref', \"No ID available\") or \"No ID available\"\n",
    "                url = getattr(dataset, 'url', \"No URL available\") or \"No URL available\"\n",
    "                description = getattr(dataset, 'description', \"No description available\") or \"No description available\"\n",
    "                last_updated = getattr(dataset, 'last_updated', \"No update date available\") or \"No update date available\"\n",
    "                size = getattr(dataset, 'size', \"No size information available\") or \"No size information available\"\n",
    "                rows = getattr(dataset, 'total_rows', \"No row information available\") or \"No row information available\"\n",
    "\n",
    "                result_text.insert(tk.END, f\"Title: {title}\\n\")\n",
    "                result_text.insert(tk.END, f\"ID: {dataset_id}\\n\")\n",
    "                result_text.insert(tk.END, f\"URL: {url}\\n\")\n",
    "                result_text.insert(tk.END, f\"Description: {description}\\n\")\n",
    "                result_text.insert(tk.END, f\"Last Updated: {last_updated}\\n\")\n",
    "                result_text.insert(tk.END, f\"Size: {size}\\n\")\n",
    "                result_text.insert(tk.END, f\"Rows: {rows}\\n\")\n",
    "                result_text.insert(tk.END, \"-----------\\n\")\n",
    "\n",
    "                # Add dataset to listbox for selection\n",
    "                dataset_listbox.insert(tk.END, dataset_id)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing dataset attributes: {e}\")\n",
    "\n",
    "def download_dataset(dataset_id, path):\n",
    "    try:\n",
    "        authenticate_kaggle()\n",
    "        kaggle.api.dataset_download_files(dataset_id, path=path, unzip=True)\n",
    "        print(f\"Dataset {dataset_id} downloaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading the dataset: {e}\")\n",
    "\n",
    "def on_download():\n",
    "    selected_index = dataset_listbox.curselection()\n",
    "    if not selected_index:\n",
    "        result_text.insert(tk.END, \"No dataset selected for download.\\n\")\n",
    "        return\n",
    "\n",
    "    dataset_id = dataset_listbox.get(selected_index[0])\n",
    "    download_path = simpledialog.askstring(\"Download Path\", \"Enter path to save dataset:\", initialvalue=os.getcwd())\n",
    "    \n",
    "    if download_path:\n",
    "        print(f\"Downloading dataset: {dataset_id}\")\n",
    "        download_dataset(dataset_id, download_path)\n",
    "        result_text.insert(tk.END, f\"Downloading dataset {dataset_id} to {download_path}...\\n\")\n",
    "\n",
    "# Set up the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Kaggle Dataset Browser\")\n",
    "\n",
    "# Search Entry\n",
    "search_label = tk.Label(root, text=\"Search Query:\")\n",
    "search_label.pack(pady=5)\n",
    "search_entry = tk.Entry(root, width=50)\n",
    "search_entry.pack(pady=5)\n",
    "\n",
    "# Tags Entry (Optional)\n",
    "tags_label = tk.Label(root, text=\"Tags (comma-separated):\")\n",
    "tags_label.pack(pady=5)\n",
    "tags_entry = tk.Entry(root, width=50)\n",
    "tags_entry.pack(pady=5)\n",
    "\n",
    "# Search Button\n",
    "search_button = tk.Button(root, text=\"Search\", command=on_search)\n",
    "search_button.pack(pady=5)\n",
    "\n",
    "# Results Area\n",
    "result_text = scrolledtext.ScrolledText(root, width=80, height=20)\n",
    "result_text.pack(pady=5)\n",
    "\n",
    "# Dataset Listbox\n",
    "dataset_listbox = tk.Listbox(root, width=80, height=5)\n",
    "dataset_listbox.pack(pady=5)\n",
    "\n",
    "# Download Button\n",
    "download_button = tk.Button(root, text=\"Download Selected Dataset\", command=on_download)\n",
    "download_button.pack(pady=5)\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
